# Test Ground Weeklys Aug 06 ~ Oct 01 2019

Originally at https://docs.google.com/document/d/1yYTXLOd-Rn9U-yfngaNJAUhiVRiZV6Rr555E4DWTYcQ/edit#

## Resources

- [Trello Board](https://trello.com/b/O9z3ljaH/testground-ignition-%F0%9F%9A%80)
- [Testing Infra Design](https://github.com/ipfs/testground/blob/master/docs/SPEC.md)
- [Testing Inventory](https://github.com/ipfs/testground/blob/master/docs/test-inventory.md)
- [Testing Improvement Tracker](https://docs.google.com/spreadsheets/d/1xyqyGUF-oe3x9ln88YonVeOMWWdknik74lVgL_3dBY8/edit#gid=0)

## Oct 01

### Agenda

- **Updates**
    - General update from the Cross Team Meeting
    - Raul
       - Done
          -
       - Next
          - All of the architecture is documented
          - Raul will send Jim notes on elastic search and what has in mind
    - Jim
       - Done
          - AWS access
          - Replicated testground DHT test on manually created EC2 machine
             (Ubuntu, Docker CE, go 1.13)
      - **Next**
        - ELK, Packer?, auto-scaling group
        - Tc
        - [P0] 2 interviews
   - David
     - Done
       - README docs
       - Test Inventory got reviewed and merged
       - Got a bunch of the the Test Plan narratives draft
https://github.com/ipfs/testground/pull/
       - Enroute Test Plan 1 (got sidetracked by a sidequest on understanding how
to use go-ipfs programmatically and got snipped by just go-ipfs docs
overall)
     - Next
       - Implement Test Plan 1
       - I’ve some open questions about
       - How should one go about doing tests with tons of data? Will
it only possible on Cloud Infra? Will we enable mounting
volumes locally of remote drives as well?

- Other items
  - Trying to give a little advance notice to other go-ipfs-capable folks across the team we
may want a week or two of help from - do we have additional thoughts/visibility into
who/when/if we’ll want their help?
  - Adrian has experience instrumenting code
  - Adin has experience with DHT
  - Adin can review the 2hr session and start getting up to speed
  - Folks shouldn’t have to understand the entirety of testground - need to
packetize so can hammer things out with a template
  - Need a pipeline where can ship a test and see what it does
  - Maybe Adin can help build the 9 tests - local stats won’t tell you much
  - Building the UI isn’t Adin’s focus - Jim needs to get that running first
- Blockers
  - Testcase 1
  - Data connection to the UI
  - Cluster to not just run locally
  - 1-3 weeks

## Sept 24

### Agenda

- Updates
    - Raul
       - New trello board:
          https://trello.com/b/O9z3ljaH/testground-ignition-%F0%9F%9A%
       - Spent 2.5 hours on Monday walking David through the Testing Infra effort
       - Raul going to continue working on the docker runner to prove an
          end-to-end running of a testcase - all the way through running 100 docker
          instances
             - After have that up, will need to shift focus entirely to DevCon - likely
                tomorrow
       - Trello board should be set up with work packages
       - Know want to use nomad > kubernetes - docker not stable enough
          - Nomad has learning curve and setup curve (wrap head around
             terraform, packer, etc)
          - Re-setup if get borked
          - Proposal - simplify container orchestration for MVP case by running
             on docker swarm
          - Easier to set up
          - Swarm - proven to work for 200K containers
          - Small step from docker runner to docker swarm runner
       - Been working on a docker runner and it’s looking pretty good! Hoping to
          finish this today/early tomorrow:
          https://github.com/ipfs/testground/blob/64088a761351888dd8217aa85a8e
          3ea64eb5778/pkg/runner/local_docker.go
       - Then we’ll have a test case fully running on docker with 200 local instances
          over a user-defined network bridge
       - Next step would be to ship those to a cluster (Docker Swarm / Nomad) —
          I’d like @jimpick to start setting that up
       - AI raul: make a little screen recording of the end to end demo with runner
          working - building testplan against commit, running on redis, getting results
          back
             - ETA tomorrow or thurs evening
       - Talked about doing a hack week between Nov 4-10 in Tenerife
    - Jim
       - AI jim: Help with setting up the infrastructure - terraform, packer, AWS, etc
          - Next step after local runner for test case is running in a cluster
       - Want a meeting for Friday with demo and walkthrough of the code
          - AI raul: schedule meeting for Friday to do code walkthrough
    - David
      - In Macau - stepping up to help DRI and project manage to compensate for
    Raul’s upcoming unavailability due to DevCon
      - AI david: Write learnings and documentation of the setup for sharing with
    others

- Timeline
  - https://github.com/ipfs/testground/issues/

- OKRs
  - Rope in David - going to own the organizational side of this project
  - [P0] Unblock the go-ipfs release train (by Oct 24)
  - Deploy a cluster and run test cases on the cluster
  - Defined 10 test cases needed for go-ipfs release
  - [P1] Able to shard this work across team members - ramping up
  - [P1.5] Testing infra usable into Q
  - We will stick notes in the slack channel for semi-async coordination

## Sept 17

### Agenda

- Updates
    - Raul (OOO): Lots of testground code landed: ​https://github.com/ipfs/testground
       - https://github.com/ipfs/testground/pull/
       - https://github.com/ipfs/testground/pull/
    - Jim: 10 initial tests and mapping exercise:
       https://github.com/ipfs/testground/pull/
- Demos
- Asks
    - Get a DNS / namespace to host the dashboard
       https://github.com/ipfs/testground/issues/
    - OKRs - Testing Infra Q
       - https://docs.google.com/spreadsheets/d/1AiNUL7vK5Jp8aa839UaMaI_AlB
          U5r6Bor-A40179I2A/edit#gid=
    - Tests
       - DHT
       - Bitswap
       - ???

- Open questions:
- where are we going to shove logs? Is there still a sidecar?
- Where should we start putting benchmarks?
- Can we agree that for now we are going to use this particular grafana
instance at benchmarks.ipfs.team?
- Want to make progress on the tests
- DHT.toml - currently can run these locally
- Take the DHT test and write a bitswap test of spinning up 100 nodes and sending
blocks between then
- And DOCUMENT this
- Sync and runtime - runtime is shipping out metrics to something, and sync talks to redis to
watch for and send events
- Is there something with x notes running version 1 and y nodes running version 2?
- What specific test cases are required to prove out 0.5.0 changes
- NAT is lower priority than DHT and bitswap
- Can test Circuit Relay and WebRTC Turn which are always way to overcome
NATs
- Need to test where some nodes are natted / un-dialable -- don’t need to test NAT
itself
- Disable TCP transports & enable listening on ___ - creates condition want to test
to begin with
- Later improvements

- Dialable but only through relays
- Nodes go back and forth between being dialable and undialable - back and
    forth
- Nodes are dialable by certain nodes and not other nodes
- Test bitswap and the DHT when have many nodes and many NAT’d nodes
- Bitswap
- **(ONE)** ​spin up X nodes, were Y have desired data - try to spread data to all X
nodes
- Nodes with data have latencies and bandwidth constraints -
- DHT (content routing)
- add xx,000 nodes to DHT, try to find and get desired data on one node
- add xx,000 nodes to DHT with half running 0.4.22 and half running
master/nightly/etc, try to find and get desired data on one node
- add xx,000 nodes to DHT, where 50% / 80% / 95% are NAT'd - try to find and get
desired data on one node (that is / isn't NAT'd)
- add xx,000 nodes to DHT, where 50% / 80% / 95% are NAT'd && x percent of
nodes running new/old version - try to find and get desired data on one node (that
is / isn't NAT'd)
- ??public vs private addresses (later)
- Peer Routing over the DHT
- Both peers behind same NAT, can we find each other


- Scale
  - add XXMB to one node, unpin data as transfer to node 2, run GC?
  -
- Manifests configure the actual tests, manifests can configure across multiple plans
- Need to improve the plan to 1. Pick versions of IPFS, 2. Pick NAT config, 3. Ephemeral
nodes (reboot every X seconds)
- Changing IP address // running GC → things to add in later
- Test cases
- Everyone asking for different types of data vs everyone asking for the same data
- Where do we expect to be (configure switches), then test IPFS
-
- (David) One thing to consider (requires more crafting) is having test setups that are generated
based on a narrative of nodes with roles e.g. : Spin 1000 nodes, %10 are behind single NAT,
%10 behind double NAT, %10 crash every 30 seconds, %10 change their multiaddrs every 2
mins, the rest are on public IPs behaving correctly. And then have a way to capture all the logs
and reproduce what happened, Filecoin Network Visualizer style
- One comment: For example —
https://github.com/ipfs/interop/blob/master/test/circuit/all.js#L15-L69 — tests that Circuit Relay
works in any kind of combination of 3 nodes of both types (JS and Go). What it doesn’t test is that
a node is able to look for available relay nodes in the public infrastructure.
- I guess we can replicate the public infra in test ground, nevertheless, shall we consider
integration tests with the live network at this stage so that we can be even more sure that
everything is perfect?
-
- Todo:


- Jim: Run DHT test
    - Use this tool
    - Writing test plans
       - Write a test for bitswap
       - Add top three things to the manifest
    - Hooking things up and doing comparisons
- Consume stdout
- Will need to do librarian duty on the dashboard to make them accessible
- Jim: ping alex about getting access to benchmarks:
    https://github.com/ipfs/benchmarks/blob/master/infrastructure/inventory/inventory.yaml
-

## Sept 10

- Agenda
    - Updates
    - Demos
    - Timelines
    -
- Notes
    - Raul
       - Fully operational sync service - 100 DHT nodes running on his machine, syncing
          via redis, listen for eachother in the redis instance, add them into routing tables
          and try to find each other
    - Jim
       - Working on the traffic shaping - using TC command - starting with one simple thing
          to limit bandwidth in and out
    - Demos
       - Testground
    - Architecture
       - Codebase monolithic
          - May want different test plans in different repos in the future
          - Using go-plugins? - don’t work all that well and very finnecky about making
             sure all the build conditions are exactly the same
                - Look into pre-loaded modules - a script (go-generate) to pull them
                   all in
          - Want test plans to avoid re-containing much of the testbed code
    - Timelines
       - 10 high-value test cases that are producing reproducible metrics and show
          varience across commits and general stability of the network
       - Raul is out next week and then prepping for devcon
       - Aiming to remove self as blocker by EOWeek
       - Once core build pipeline landed jim will take this on as active development
       - Need to settle higher level expectations on what to test
          - Lets define what those are at high detail
       - Have by eoweek


## Sept 3

- Agenda
    -
    -
- Notes
    - Raul - building primitives for testing framework and using console for synchronization
       - Creating a command that receives testplan and test case
       - Have local runner and nomad runner
       - Will have one test case working for the local runner
       - Next steps - nomad runner, metrics ingestion, more test cases matching local
          skeleton - all parallelizable
       - Should be able to take a series of dependencies to commits
          - Docker image of the test case and right dependencies such that testplan
             now targets the right set of commits
       - Via nomad going to be running an executable once per node - this is the sidecar
          agent
             - Vector (​https://vector.dev/​) - new filebeat etc - watch the stream of events
                and ship them to influxdb
             - Should assume there is a process following the node and collecting output
                and
             - Reusing the datastore setup for js/benchmarks under a different domain for
                now. Will get a better sense of what we need and will have to deploy our
                own setup with all the various clusters
                   - Will have an infra request to help get set up, but within the team
                      should be able to handle day to day of infra
                   - In general - having an embedded infra capability will be useful
                   - For now - having a dedicated AWS account to unblock makes
                      sense
                   - Be scrappy to get the job done - lets aim to unblock the next 2-
                      months in the short term before automating
             - Definitely going to need to spin up and sping down nodes for testing (since
                prohibitively large)
    - Jim - hooked in the work Raul did and plugged it into Google cloud run
       - Took bitswap and added “jim” events
       - Can run any ipfs command and see what the nodes do w/ DHT queries
       - Need to add on “am I connected to this node?”
       - Can record event log and send it to nomad - all timestamped so can go back and
          forth in time and capture full traces
       - Something like --stat to see how it unravels
       - A “top” command with a live view updating with whatever the node is doing
       - Using the http api to consume the logs from any ipfs node
       - Focus for now - ability to measure and test new releases
    - Molly - where are we on ETA given current status? What is the fastest path we can take to
       unblocking go-ipfs?


- Creating test cases that conform to the pattern in the repo will be really useful
- Towards EOQ - have a tool that can run with an ipfs commit and print out results
    from different test cases using nomad - deploying these test cases within a cluster
    and archiving within an influxdb
- Won’t have all the presentation by EOQ, but will have it in raw format and can
    create queries in grafana analyzing output
- Being able to run in cluster on a single command and get an output back
- Want to have this automated - ex with a github action so don’t have to ssh in every
    night
- If can @ something and have a nightly deploy, that will do it
- Dashboard work would be unblocked with knowing what the data is going to work
    like
       - What would it take to start that thread now
       - Dashboard would pull from influxdb
       - Still need to make dashboard in grafana and make them public and point at
          current test infra that we have
       - Produce a set of sample/mock data with a data model that could load into
          influxdb - then need to get the comparative graphs
       - You should be able to compare master vs PR X by writing a simple
          cookbook query that then spits out the desired graph
       - Can do js generated graphs in grafana, or have something that hits the
          grafana API and manually creates dashboards
- Need over time these numbers are going up - dates, tests, and KPI per test - red
    or green if up or down vs master
- If time series scoped to a particular branch would make sense
- Make the github action comment on the PR to add a comment with a link to the run
- AIs
- Raul flesh out the parallelizable tracks of work out of the test infra work into an
issue or doc
- Raul and Jim meet
- Molly extend meeting to 45 min going forward

## Aug 27, 2019 Meeting

- Agenda
    - Jim's Demo.
    - "Next steps"
    - (molly) What is our current ETA to get sufficient network testing to unblock the next go-ipfs
       release?
    -
- Notes
    - Raul wants to launch a test case that exercises the DHT and creates a private network
       with at least 100 nodes running over a set of commits from github and outputting metrics
       in our influx DB we already have
    - Design doc - where can folks jump in with the things that already exist vs need to start on


- Aim is POC that lands the high level interfaces and test cases - create enough structure in
    the codebase that we can define frontend interfaces
- Cole is going to pick up packet orientation with contributions to testlab

## Aug 13, 2019 Meeting

- Agenda
    - Hiring: Tech Lead, Distributed Systems Test Infrastructure - please review the draft ​job
       description​ and update to meet your needs! (dietrich)
- Notes
    - Nightly Gateway/Bootstrapper: ​https://github.com/protocol/bifrost-infra/issues/
    - Shared Docker image amongst testlab / Gateway / official release:
       https://github.com/ipfs/go-ipfs/pull/
          - Infra side would like to use same docker image everywhere - want to be able to
             configure docker through environment variables
          - Ideally want testlab to use the same image - official CI/CD pipeline
          - Want to be able to override standard config values in IPFS based on a new image
          -
-

Dietrich: help me help you! First time here. Help review the JD, we need this review before we can get
the pipeline going. Just a barebones description for now, based on previous openings for infra. For
specifics for this work, tech lead for this area, please add as much detail and Dietrich will go back and
give some shade and love. P0.

Molly: prioritization came from IPFS team week. Where testing work was identified. Raúl stepped up
temporarily, but we need someone to permanently own this role and the testing infra.

Raúl: deadline? D: up to you. Molly: some promising candidates, including person who worked on
Google Borg. Everybody to add thoughts and input to the doc. Iterate and finish by ​ **end of this week.**

S: people with leadership experience.

Raúl: have a prototype, wrote the design doc for testing infra
(​https://docs.google.com/document/d/1jToUP0E0of0WSnLv7gdIEXXQgfscIaxq_aEbwCMPN28/edit#​),
Cole is going to work on the large scale private network of things

Hector: moved all metrics to single grafana. Debugging an incident - able to grab memory and go routine
dumps

Steven: talked with bifrost about having nightly bootstrappers and gateways. Problem is continuous
deployments. Want build infra to be as close as possible to production. The metrics on gateway
performance will feed into gateway metrics (nightly mirror data will be real data - need to keep data /
metrics confidential)


- Test pipeline should continue with idea of producing docker images for own purposes and
    publishing in docker hub for own scenario / architecture, knowing that whatever is run on the
    gateway should be equivalent

Jim - Js-benchmark improvement needs merging from Alan. To add more dashboards in grafana - need
credentials.
Idea: integrate js-benchmarks into testing infra pipeline by cloning repo - output metrics on std out so can
be shipped to influx db

- Can integrate all those benchmarks into testing pipeline
- Run them on bare-metal hardware so very reproducible, new path is running on docker
- Want to get comparative view across commits
- Not looking at “perf of IPFS” but relative improvement / etc of commits
- Want the isolation that docker gives you
-

## Aug 6, 2019 Meeting

- Agenda
    - Infra update
    - Benchmarks update
    - Review the plan
    - Organizational Qs
- Notes
    - Raul working on testing infra design:
       https://docs.google.com/document/d/1jToUP0E0of0WSnLv7gdIEXXQgfscIaxq_aEbwCMP
       N28/edit#
          - Architecture aims to be generic enough for any test case or plan, feeding from
             environment variable params, outputting test results on stdout
          - Using Nomad & sidecar
             - Understand what’s running, fetch profiles, know context of test run, and
                ship artifacts to archive service
    - Cole - would like to be integrated on getting testlab in use
       - Would like to help implement / design the sidecar service
       - Using local docker api to watch everything that gets planned to know what test
          cases / rounds are running on that machine
       - Think there’s a chunk of work already done in this direction
       - Is the testlab being used for test infra project?
          - Yes - but tbd in what form - as a building block
          - Current architecture is a wishlist, not a full spec yet
          - Testlab is moldable to our needs
          - Aiming for design doc done by EOWeek
    - Organizational Qs
       - Recordings?
          - Yes? Unless there’s a reason this might be sensitive / private


- Github issue?
    - Test pipeline repo might be the right place?
       https://github.com/ipfs/test-pipeline
- Focus of this team - technical project to build the infra - part of the larger testing
    endeavor happening in other groups
       - This is an on-topic call - let’s keep it so!
- Gateway team not pushing on a nightly bootstrapper / canary right now - Steb to
    jump in on that meeting to re-kick onto agenda
-
- IPFS Benchmarks - benchmarks.ipfs.team
- Demo of benchmarks repo running against go-ipfs
- Added a switch to pass in go-ipfs param
- Builds go-ipfs from scratch using latest master
- Grafana is the gui, has an influxdb
- Currently has one graph with all the test on it - all smushed together in one
dashboard
- Did some work on dashboards to separate out
- Running subset of tests every 10 mins
- Reorganized dashboards into js-minion (running js-ipfs), go-minion (running
go-ipfs)
- Experimented with many graphs vs multi-select on a single graph
- Should use grafana to build the dashboards
- Access to set up dashboards in their own scaffolded areas to experiment
and play around
- What it can do is really powerful
- Github permissions maybe to be able to modify?
- @alan take a pass at what to merge in there
- Now that we have ability to build go, then worth putting those dashboards on
production
- If can’t figure out how to add, ask in the benchmarks repo
- Can also link to other things from grafana
- Won’t back up the data - need to think about this - hosted etc?
- @Jim - create an issue for these open questions / next steps
- Could pull in the spec issue about a commit into the dashboard (would need more
work)
- Need more work on go-ipfs benchmarks
- Could hook in testlab into this, but don’t want to reproduce effort here
- 1. Larger network simulation (want to run constantly)
- 2. Network canary
- 3. Node to node benchmarks
- Spin up a few node and run the benchmarks
- Are there more things we can reuse?
- Right now benchmarks are sequential, do we have to rewrite to make it scalable?
- Steb and Raul to discuss more given more research
- AIs
- Steb to check in on gateway canary
- Alan/Jim to write up issue and tag this group on benchmark open Qs


- Raul to share out iterations on draft and ask for group feedback


